# This specifies the number of layers and number of hidden neurons in each layer.
# Note that the first and the last elements of the list indicate the input and
# output sizes
layer_specs: [3072, 128, 10]  #Represents a 2 layer NN. 3072 is the input layer

# Type of non-linear activation function to be used for the layers. Default is tanh.
activation: "tanh"

# The learning rate to be used for training.
learning_rate: 0.00001

# L2 regularization parameter
isL2: False

# Regularization constant lamda
regularization: 0

# Use momentum for training
momentum: True

# Value for the parameter 'gamma' in momentum
momentum_gamma: 0

#Weight Type
weight_type: "random"

#Epsilon for gradient check
Epsilon: 0.01

#Index for the gradient needed to check
Index: [1, 0, 1]